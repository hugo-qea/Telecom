{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "633b97aa",
   "metadata": {},
   "source": [
    "# Numerical analysis: TP-1\n",
    "<h4 align=\"right\"> Author: <i> Hicham Janati </i></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcb568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c945eaa",
   "metadata": {},
   "source": [
    "#### 1) Integers and floating point representations\n",
    "run the following cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6171e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is equal to [2] and its type is int64.\n"
     ]
    }
   ],
   "source": [
    "a = 2 * np.ones(1).astype(int)\n",
    "print(f\"a is equal to {a} and its type is {a.dtype}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ad1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ** 60 = [1152921504606846976]\n",
      "2 ** 61 = [2305843009213693952]\n",
      "2 ** 62 = [4611686018427387904]\n",
      "2 ** 63 = [-9223372036854775808]\n",
      "2 ** 64 = [0]\n",
      "2 ** 65 = [0]\n",
      "2 ** 66 = [0]\n",
      "2 ** 67 = [0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(60, 68):\n",
    "    print(f\"2 ** {i} = {a ** i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac01966",
   "metadata": {},
   "source": [
    "**Q1.  Can you explain the observed behavior ?  Propose a way to fix this.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c939e78",
   "metadata": {},
   "source": [
    "Overflow car les nombres entiers sont ici représentés sur 64 bits (donc 63 bits pour la valeur car il y a le bit de poids fort qui est le bit du signe). Pour éviter le problème, on peut choisir d'augmenter la mémoire allouée pour pouvoir écrire les nombres sur plus de bits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae02a39a",
   "metadata": {},
   "source": [
    "**Q2. Does the problem occur without specifying the dtype `np.ones(1)`? Deduce a real numpy usecase where this might be a problem.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ac7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "574334e9",
   "metadata": {},
   "source": [
    " In deep learning applications, chosing the \"right\" dtype is a very important tradeoff between speed and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7540a340",
   "metadata": {},
   "source": [
    "#### 2) Imperfect floating point numbers "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b8c4ad",
   "metadata": {},
   "source": [
    "Consider the function $f(x) = 2x$ on $[0, 0.5]$ and $f(x) = 2x - 1$ on $]0.5, 1]$ \n",
    "\n",
    "**Q1.** Consider the sequence defined by $x_{n+1} = f(x_n)$ with $x_0 = 0.1$ Compute the first 5 elements of the sequence (manually). What do you conclude ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f6edb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is equal to 0.1 and its type is <class 'float'>.\n",
      "x is equal to 0.2 and its type is <class 'float'>.\n",
      "x is equal to 0.4 and its type is <class 'float'>.\n",
      "x is equal to 0.8 and its type is <class 'float'>.\n",
      "x is equal to 0.6000000000000001 and its type is <class 'float'>.\n",
      "x is equal to 0.20000000000000018 and its type is <class 'float'>.\n"
     ]
    }
   ],
   "source": [
    "x = 0.1\n",
    "print(f\"x is equal to {x} and its type is {type(x)}.\")\n",
    "for k in range(5):\n",
    "    if x > 0.5:\n",
    "        x = 2 * x - 1\n",
    "    else:\n",
    "        x = 2 * x\n",
    "    print(f\"x is equal to {x} and its type is {type(x)}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703140fd",
   "metadata": {},
   "source": [
    "**Q2.** Complete the function below that returns $x_n$. What do you observe ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdcc7d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = 0.1\n",
    "\n",
    "def f(x, n=100):\n",
    "    for k in range(n+1):\n",
    "       if x > 0.5:\n",
    "        x = 2 * x - 1\n",
    "    else:\n",
    "        x = 2 * x \n",
    "    return x\n",
    "\n",
    "f(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b37811e",
   "metadata": {},
   "source": [
    "`float64` numbers are represented using 64 bits as:\n",
    "$$(-1)^s \\quad 0.m_1..m_{52} \\quad 2^{e_1..e_{11}}$$\n",
    "where $s$ is a sign bit, $m$ is the mantissa (52 bits) and $e$ is the exponent (11 bits)\n",
    "\n",
    "**Q4** Take a moment a contemplate this mystery. Use the `pretty_float_bits` function below to find an explanation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7363c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30000000000000004"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f833b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 01111111011 1001100110011001100110011001100110011001100110011010'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def float_to_bin(f) -> str:\n",
    "    fmt = \">d\"\n",
    "    bz = struct.pack(fmt, f)\n",
    "    return \"\".join(f\"{b:08b}\" for b in bz)\n",
    "\n",
    "def sign_exponent_fraction(s):\n",
    "    return s[0:1], s[1:12], s[12:64]\n",
    "\n",
    "def pretty_float_bits(f) -> str:\n",
    "    return \" \".join(sign_exponent_fraction(float_to_bin(f)))\n",
    "\n",
    "pretty_float_bits(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c26306b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 01111111101 0011001100110011001100110011001100110011001100110100'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_float_bits(0.1 + 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc455468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 01111111101 0011001100110011001100110011001100110011001100110011'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretty_float_bits(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da88dae4",
   "metadata": {},
   "source": [
    "With floats, the order matters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd92c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100. - 100. + 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb985cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09999999999999432"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1 + 100. - 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e670da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "517bb030",
   "metadata": {},
   "source": [
    "#### 3) Machine precision and cumulative errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeaccf4",
   "metadata": {},
   "source": [
    "Consider the integral $$I_n = \\int_{0}^1 \\frac{x^n}{x + 10}dx$$\n",
    "\n",
    "1. Without computing $I_n$, find its limit.\n",
    "2. Compute $I_0$ and find a recurrence formula between $I_{n+1}$ and $I_n$\n",
    "3. If we were to compute $I_n$ recursively, would that algorithm be stable numerically ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a180643",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "$$ \\lim I_n = 0$$\n",
    "\n",
    "2.\n",
    "\n",
    "$$ I_0 = \\int_0^1 \\frac{1}{x+10} dx = [\\ln (x+10)]_0^1 = \\ln(\\frac{11}{10})$$\n",
    "\n",
    "$$ I_{n+1} = \\frac{1}{n+1} - 10 * I_n$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32426ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integral(i0, n):\n",
    "    ii = i0\n",
    "    for k in range(n):\n",
    "        ii = (1/(k+1)) - 10 * ii\n",
    "        print(ii)\n",
    "    return ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e39b02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04689820195675065\n",
      "0.031017980432493486\n",
      "0.023153529008398455\n",
      "0.018464709916015454\n",
      "0.015352900839845474\n",
      "0.013137658268211921\n",
      "0.011480560175023635\n",
      "0.010194398249763648\n",
      "0.009167128613474629\n",
      "0.008328713865253717\n",
      "0.007621952256553738\n",
      "0.00711381076779595\n",
      "0.005784969245117427\n",
      "0.013578878977397152\n",
      "-0.06912212310730485\n",
      "0.7537212310730486\n",
      "-7.478388781318721\n",
      "74.83944336874276\n",
      "-748.3418021084802\n",
      "7483.468021084803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7483.468021084803"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integral(np.log(11/10), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39632f2",
   "metadata": {},
   "source": [
    "4. Replace 10 in the integral with a constant A > 1. Given a machine precision variable $\\varepsilon$, how can we set the number of iterations $n$ based on a desired cumulative error E ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd09b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c131b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "print(np.finfo(float).eps) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb283da",
   "metadata": {},
   "source": [
    "**Independent questions:**\n",
    "\n",
    "**Q5.** Write a piece of code that can find $\\varepsilon$ numerically. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26e5f4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "e = 1e-12\n",
    "print(1+e == 1)\n",
    "\n",
    "e = 1e-24\n",
    "print(1 + e == 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bca24",
   "metadata": {},
   "source": [
    "**Q6.** Given what you know now, how should you test if two numbers or arrays are equal ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d1da659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0.2 + 0.1\n",
    "\n",
    "y = 0.3\n",
    "\n",
    "np.abs(x - y) / np.max(np.abs([x, y])) < 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbaf2de",
   "metadata": {},
   "source": [
    "#### 4) Logsum-exp trick\n",
    "Consider a classification model with 4 classes. We are modeling the probablity of a sample being in class $k$ with: $$p_k = \\frac{ exp(w_k)}{\\sum_{i=1}^{4} exp(w_i)}$$\n",
    "\n",
    "where $w$ are the weights of a neural net.\n",
    "1. Why does this model make sense ? \n",
    "2. Given the example $w = [-20, -1, 0, 1000]$, it is obvious which class this sample should correspond to. Compute the prediction probabilities using the function below for this particular example. Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e9f6b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wz/mdj42wg170j7vt8s9ljnyn580000gn/T/ipykernel_24859/437721929.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  p = np.exp(w)\n",
      "/var/folders/wz/mdj42wg170j7vt8s9ljnyn580000gn/T/ipykernel_24859/437721929.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  p /= p.sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0., nan])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(w):\n",
    "    p = np.exp(w)\n",
    "    p /= p.sum()\n",
    "    return p\n",
    "\n",
    "w = np.array([10, -1, 40, 2, 1000])\n",
    "predict(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d025fd",
   "metadata": {},
   "source": [
    "3. Even if we assume that $exp(w_k)$ do not overflow, computing the normalizing sum can cause problems if the number of labels is too large. After showing the following statement, propose a method to modify `predict` in order to avoid overflow errors:\n",
    "$$ \\forall c \\in \\mathbb{R} \\qquad log\\left(\\sum_{k=1}^K exp(w_k + c)\\right) =  c + log\\left(\\sum_{k=1}^K exp(w_k)\\right) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41dffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lse(w):\n",
    "\tc = np.max(w)\n",
    "\twp = w - c\n",
    "    return ll\n",
    "\n",
    "def predict_stable(w):\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c93ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_stable(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59d8043",
   "metadata": {},
   "source": [
    "4. Generate random weight vectors with `np.random.randn(K)` and test that both functions return the same probabilities. Test it with the scipy `logsumexp`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ea35d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "39d3d95e6798e0a81aaa0be7121ed551d62c61941e7cbab5aa9b27ebcddc02dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
